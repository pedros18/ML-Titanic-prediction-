{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90856,"databundleVersionId":10625683,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\ntrain = pd.read_csv('/kaggle/input/soai-lab-titanic-survival-prediction-challenge/train_titanic.csv')\ntest = pd.read_csv('/kaggle/input/soai-lab-titanic-survival-prediction-challenge/test_titanic.csv')\nsample_submission = pd.read_csv('/kaggle/input/soai-lab-titanic-survival-prediction-challenge/sample_submission.csv')\n\n# brief data describtion \nprint(train.info())\nprint(train.describe())\n\n# missing values\ndef handle_missing_values(data):\n    data['fare'].fillna(data['fare'].median(), inplace=True)\n    data['age'].fillna(data['age'].median(), inplace=True)\n    data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n    data.drop(['cabin'], axis=1, inplace=True) \n    return data\n\ntrain = handle_missing_values(train)\ntest = handle_missing_values(test)\n\n# feature engineering\ndef featureng(data):\n    data['Title'] = data['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    title_mapping = {\n        'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 6,\n        'Col': 7, 'Major': 7, 'Mlle': 2, 'Countess': 3, 'Ms': 2, 'Lady': 3, 'Jonkheer': 1,\n        'Don': 1, 'Dona': 3, 'Mme': 3, 'Capt': 7, 'Sir': 1\n    }\n    data['Title'] = data['Title'].map(title_mapping).fillna(0)\n    data['FamilySize'] = data['sibsp'] + data['parch'] + 1\n    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n    data.drop(['name', 'ticket', 'sibsp', 'parch'], axis=1, inplace=True)\n    return data\n\ntrain = featureng(train)\ntest = featureng(test)\n\n# drop target and let features\ny = train['survived']\nX = train.drop(['PassengerId', 'survived'], axis=1)\nX_test = test.drop(['PassengerId'], axis=1)\n\n#important to check if the column is categorical or numerical to change it later\ncategorical_columns = ['sex', 'embarked', 'boat', 'home.dest', 'Title']\nnumeric_columns = ['pclass', 'age', 'fare', 'body', 'FamilySize', 'IsAlone']\n\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),  # Fill missing numeric values with mean\n    ('scaler', StandardScaler())                 # Scale numeric values\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Fill missing categorical values\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))                      # One-hot encode categorical values\n])\n\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_columns),\n        ('cat', categorical_transformer, categorical_columns)\n    ]\n)\n\n# preprocessing\nX = preprocessor.fit_transform(X)\nX_test = preprocessor.transform(X_test)\n\n# data split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nparam_grids = {\n    'logistic regression': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga']},\n    'random forest': {'n_estimators': [100, 200], 'max_depth': [10, 20, None]},\n    'gradient boosting': {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n    'svm': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']},\n    'knn': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n    'xgbboost': {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5, 7]}\n}\n\nmodels = {\n    'logistic regression': LogisticRegression(max_iter=1000),\n    'random forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'gradient boosting': GradientBoostingClassifier(random_state=42),\n    'svm': SVC(),\n    'knn': KNeighborsClassifier(),\n    'xgbboost': XGBClassifier(eval_metric='logloss')\n}\n\nbest_score = 0\nbest_model = ''\n\nfor name, modele in models.items():\n    grid_search = GridSearchCV(modele, param_grids[name], cv=5, scoring='f1', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    pred = grid_search.best_estimator_.predict(X_val)\n    score = f1_score(y_val, pred)\n    print(f'{name} score: {score:.5f}')\n    if score > best_score:\n        best_model = grid_search.best_estimator_\n        best_score = score\n\n# cv for best model\ncvscore = cross_val_score(best_model, X, y, cv=5, scoring='f1', n_jobs=-1)\nprint(f'best modele: {best_model.__class__.__name__}')\nprint(f'cross validation score is: {cvscore.mean():.5f}')\n\n#submission\nfinal_pred = best_model.predict(X_test)\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': final_pred})\nsubmission.to_csv('submission.csv', index=False)\nprint('Submission file saved as submission.csv')\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:54:20.485830Z","iopub.execute_input":"2024-12-30T11:54:20.486193Z","iopub.status.idle":"2024-12-30T11:54:48.285052Z","shell.execute_reply.started":"2024-12-30T11:54:20.486167Z","shell.execute_reply":"2024-12-30T11:54:48.284021Z"}},"outputs":[],"execution_count":null}]}